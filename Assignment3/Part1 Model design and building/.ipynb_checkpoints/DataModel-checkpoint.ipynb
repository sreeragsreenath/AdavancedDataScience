{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Downloading https://files.pythonhosted.org/packages/81/a7/4179e6ebfd654bd0eac0b9c06125b8b4c96a9d0a8ff9e9507eb2a26d2d7e/imblearn-0.0-py2.py3-none-any.whl\n",
      "Collecting imbalanced-learn (from imblearn)\n",
      "  Downloading https://files.pythonhosted.org/packages/80/a4/900463a3c0af082aed9c5a43f4ec317a9469710c5ef80496c9abc26ed0ca/imbalanced_learn-0.3.3-py3-none-any.whl (144kB)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\chuda\\anaconda3\\envs\\ads-assignment1\\lib\\site-packages (from imbalanced-learn->imblearn)\n",
      "Requirement already satisfied: numpy in c:\\users\\chuda\\anaconda3\\envs\\ads-assignment1\\lib\\site-packages (from imbalanced-learn->imblearn)\n",
      "Requirement already satisfied: scipy in c:\\users\\chuda\\anaconda3\\envs\\ads-assignment1\\lib\\site-packages (from imbalanced-learn->imblearn)\n",
      "Installing collected packages: imbalanced-learn, imblearn\n",
      "Successfully installed imbalanced-learn-0.3.3 imblearn-0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 9.0.1, however version 9.0.3 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas_profiling in c:\\users\\chuda\\anaconda3\\envs\\ads-assignment1\\lib\\site-packages\n",
      "Requirement already satisfied: pandas>=0.19 in c:\\users\\chuda\\anaconda3\\envs\\ads-assignment1\\lib\\site-packages (from pandas_profiling)\n",
      "Requirement already satisfied: jinja2>=2.8 in c:\\users\\chuda\\anaconda3\\envs\\ads-assignment1\\lib\\site-packages (from pandas_profiling)\n",
      "Requirement already satisfied: six>=1.9 in c:\\users\\chuda\\anaconda3\\envs\\ads-assignment1\\lib\\site-packages (from pandas_profiling)\n",
      "Requirement already satisfied: matplotlib>=1.4 in c:\\users\\chuda\\anaconda3\\envs\\ads-assignment1\\lib\\site-packages (from pandas_profiling)\n",
      "Requirement already satisfied: python-dateutil>=2 in c:\\users\\chuda\\anaconda3\\envs\\ads-assignment1\\lib\\site-packages (from pandas>=0.19->pandas_profiling)\n",
      "Requirement already satisfied: numpy>=1.9.0 in c:\\users\\chuda\\anaconda3\\envs\\ads-assignment1\\lib\\site-packages (from pandas>=0.19->pandas_profiling)\n",
      "Requirement already satisfied: pytz>=2011k in c:\\users\\chuda\\anaconda3\\envs\\ads-assignment1\\lib\\site-packages (from pandas>=0.19->pandas_profiling)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\chuda\\anaconda3\\envs\\ads-assignment1\\lib\\site-packages (from jinja2>=2.8->pandas_profiling)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\chuda\\anaconda3\\envs\\ads-assignment1\\lib\\site-packages (from matplotlib>=1.4->pandas_profiling)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\chuda\\anaconda3\\envs\\ads-assignment1\\lib\\site-packages (from matplotlib>=1.4->pandas_profiling)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 9.0.1, however version 9.0.3 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in c:\\users\\chuda\\anaconda3\\envs\\ads-assignment1\\lib\\site-packages\n",
      "Requirement already satisfied: widgetsnbextension~=3.2.0 in c:\\users\\chuda\\anaconda3\\envs\\ads-assignment1\\lib\\site-packages (from ipywidgets)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in c:\\users\\chuda\\anaconda3\\envs\\ads-assignment1\\lib\\site-packages (from ipywidgets)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\chuda\\anaconda3\\envs\\ads-assignment1\\lib\\site-packages (from ipywidgets)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in c:\\users\\chuda\\anaconda3\\envs\\ads-assignment1\\lib\\site-packages (from ipywidgets)\n",
      "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in c:\\users\\chuda\\anaconda3\\envs\\ads-assignment1\\lib\\site-packages (from ipywidgets)\n",
      "Requirement already satisfied: notebook>=4.4.1 in c:\\users\\chuda\\anaconda3\\envs\\ads-assignment1\\lib\\site-packages (from widgetsnbextension~=3.2.0->ipywidgets)\n",
      "Requirement already satisfied: ipython_genutils in c:\\users\\chuda\\anaconda3\\envs\\ads-assignment1\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in c:\\users\\chuda\\anaconda3\\envs\\ads-assignment1\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets)\n",
      "Requirement already satisfied: jupyter_core in c:\\users\\chuda\\anaconda3\\envs\\ads-assignment1\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets)\n",
      "Requirement already satisfied: six in c:\\users\\chuda\\anaconda3\\envs\\ads-assignment1\\lib\\site-packages (from traitlets>=4.3.1->ipywidgets)\n",
      "Requirement already satisfied: decorator in c:\\users\\chuda\\anaconda3\\envs\\ads-assignment1\\lib\\site-packages (from traitlets>=4.3.1->ipywidgets)\n",
      "Requirement already satisfied: tornado>=4.0 in c:\\users\\chuda\\anaconda3\\envs\\ads-assignment1\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets)\n",
      "Requirement already satisfied: jupyter-client in c:\\users\\chuda\\anaconda3\\envs\\ads-assignment1\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\users\\chuda\\anaconda3\\envs\\ads-assignment1\\lib\\site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets)\n",
      "Requirement already satisfied: jedi>=0.10 in c:\\users\\chuda\\anaconda3\\envs\\ads-assignment1\\lib\\site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\chuda\\anaconda3\\envs\\ads-assignment1\\lib\\site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets)\n",
      "Requirement already satisfied: simplegeneric>0.8 in c:\\users\\chuda\\anaconda3\\envs\\ads-assignment1\\lib\\site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets)\n",
      "Requirement already satisfied: prompt_toolkit<2.0.0,>=1.0.4 in c:\\users\\chuda\\anaconda3\\envs\\ads-assignment1\\lib\\site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets)\n",
      "Requirement already satisfied: pygments in c:\\users\\chuda\\anaconda3\\envs\\ads-assignment1\\lib\\site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets)\n",
      "Requirement already satisfied: colorama in c:\\users\\chuda\\anaconda3\\envs\\ads-assignment1\\lib\\site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\chuda\\anaconda3\\envs\\ads-assignment1\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.2.0->ipywidgets)\n",
      "Requirement already satisfied: nbconvert in c:\\users\\chuda\\anaconda3\\envs\\ads-assignment1\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.2.0->ipywidgets)\n",
      "Requirement already satisfied: Send2Trash in c:\\users\\chuda\\anaconda3\\envs\\ads-assignment1\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.2.0->ipywidgets)\n",
      "Requirement already satisfied: terminado>=0.8.1 in c:\\users\\chuda\\anaconda3\\envs\\ads-assignment1\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.2.0->ipywidgets)\n",
      "Requirement already satisfied: pyzmq>=13 in c:\\users\\chuda\\anaconda3\\envs\\ads-assignment1\\lib\\site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\chuda\\anaconda3\\envs\\ads-assignment1\\lib\\site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets)\n",
      "Requirement already satisfied: parso==0.1.* in c:\\users\\chuda\\anaconda3\\envs\\ads-assignment1\\lib\\site-packages (from jedi>=0.10->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\chuda\\anaconda3\\envs\\ads-assignment1\\lib\\site-packages (from prompt_toolkit<2.0.0,>=1.0.4->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\chuda\\anaconda3\\envs\\ads-assignment1\\lib\\site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.2.0->ipywidgets)\n",
      "Requirement already satisfied: mistune>=0.7.4 in c:\\users\\chuda\\anaconda3\\envs\\ads-assignment1\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.2.0->ipywidgets)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in c:\\users\\chuda\\anaconda3\\envs\\ads-assignment1\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.2.0->ipywidgets)\n",
      "Requirement already satisfied: bleach in c:\\users\\chuda\\anaconda3\\envs\\ads-assignment1\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.2.0->ipywidgets)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\chuda\\anaconda3\\envs\\ads-assignment1\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.2.0->ipywidgets)\n",
      "Requirement already satisfied: testpath in c:\\users\\chuda\\anaconda3\\envs\\ads-assignment1\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.2.0->ipywidgets)\n",
      "Requirement already satisfied: html5lib!=1.0b1,!=1.0b2,!=1.0b3,!=1.0b4,!=1.0b5,!=1.0b6,!=1.0b7,!=1.0b8,>=0.99999999pre in c:\\users\\chuda\\anaconda3\\envs\\ads-assignment1\\lib\\site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.2.0->ipywidgets)\n",
      "Requirement already satisfied: webencodings in c:\\users\\chuda\\anaconda3\\envs\\ads-assignment1\\lib\\site-packages (from html5lib!=1.0b1,!=1.0b2,!=1.0b3,!=1.0b4,!=1.0b5,!=1.0b6,!=1.0b7,!=1.0b8,>=0.99999999pre->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.2.0->ipywidgets)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 9.0.1, however version 9.0.3 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: luigi in c:\\users\\chuda\\anaconda3\\envs\\ads-assignment1\\lib\\site-packages\n",
      "Requirement already satisfied: tornado<5,>=4.0 in c:\\users\\chuda\\anaconda3\\envs\\ads-assignment1\\lib\\site-packages (from luigi)\n",
      "Requirement already satisfied: python-daemon<3.0 in c:\\users\\chuda\\anaconda3\\envs\\ads-assignment1\\lib\\site-packages (from luigi)\n",
      "Requirement already satisfied: setuptools in c:\\users\\chuda\\anaconda3\\envs\\ads-assignment1\\lib\\site-packages (from python-daemon<3.0->luigi)\n",
      "Requirement already satisfied: docutils in c:\\users\\chuda\\anaconda3\\envs\\ads-assignment1\\lib\\site-packages (from python-daemon<3.0->luigi)\n",
      "Requirement already satisfied: lockfile>=0.10 in c:\\users\\chuda\\anaconda3\\envs\\ads-assignment1\\lib\\site-packages (from python-daemon<3.0->luigi)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 9.0.1, however version 9.0.3 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install imblearn\n",
    "!pip install pandas_profiling\n",
    "!pip install ipywidgets \n",
    "!pip install luigi \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Collection and Transformations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import time\n",
    "import pickle\n",
    "from sklearn.preprocessing import Imputer, StandardScaler\n",
    "\n",
    "# Statistical Testing\n",
    "# import statsmodels.api as sm\n",
    "# from statsmodels.formula.api import ols\n",
    "import scipy\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import learning_curve, validation_curve\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import ExtraTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "# Class imbalance \n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import make_pipeline\n",
    "\n",
    "# Plotting \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "plt.rcParams['figure.figsize'] = [10,8]\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WAP001</th>\n",
       "      <th>WAP002</th>\n",
       "      <th>WAP003</th>\n",
       "      <th>WAP004</th>\n",
       "      <th>WAP005</th>\n",
       "      <th>WAP006</th>\n",
       "      <th>WAP007</th>\n",
       "      <th>WAP008</th>\n",
       "      <th>WAP009</th>\n",
       "      <th>WAP010</th>\n",
       "      <th>...</th>\n",
       "      <th>WAP520</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>FLOOR</th>\n",
       "      <th>BUILDINGID</th>\n",
       "      <th>SPACEID</th>\n",
       "      <th>RELATIVEPOSITION</th>\n",
       "      <th>USERID</th>\n",
       "      <th>PHONEID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>-7541.2643</td>\n",
       "      <td>4.864921e+06</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>1371713733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>-7536.6212</td>\n",
       "      <td>4.864934e+06</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>1371713691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>-97</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>-7519.1524</td>\n",
       "      <td>4.864950e+06</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>1371714095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>-7524.5704</td>\n",
       "      <td>4.864934e+06</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>1371713807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>-7632.1436</td>\n",
       "      <td>4.864982e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>1369909710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 529 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   WAP001  WAP002  WAP003  WAP004  WAP005  WAP006  WAP007  WAP008  WAP009  \\\n",
       "0     100     100     100     100     100     100     100     100     100   \n",
       "1     100     100     100     100     100     100     100     100     100   \n",
       "2     100     100     100     100     100     100     100     -97     100   \n",
       "3     100     100     100     100     100     100     100     100     100   \n",
       "4     100     100     100     100     100     100     100     100     100   \n",
       "\n",
       "   WAP010     ...      WAP520  LONGITUDE      LATITUDE  FLOOR  BUILDINGID  \\\n",
       "0     100     ...         100 -7541.2643  4.864921e+06      2           1   \n",
       "1     100     ...         100 -7536.6212  4.864934e+06      2           1   \n",
       "2     100     ...         100 -7519.1524  4.864950e+06      2           1   \n",
       "3     100     ...         100 -7524.5704  4.864934e+06      2           1   \n",
       "4     100     ...         100 -7632.1436  4.864982e+06      0           0   \n",
       "\n",
       "   SPACEID  RELATIVEPOSITION  USERID  PHONEID   TIMESTAMP  \n",
       "0      106                 2       2       23  1371713733  \n",
       "1      106                 2       2       23  1371713691  \n",
       "2      103                 2       2       23  1371714095  \n",
       "3      102                 2       2       23  1371713807  \n",
       "4      122                 2      11       13  1369909710  \n",
       "\n",
       "[5 rows x 529 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingData= pd.read_csv(\"data/trainingData.csv\")\n",
    "trainingData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WAP001</th>\n",
       "      <th>WAP002</th>\n",
       "      <th>WAP003</th>\n",
       "      <th>WAP004</th>\n",
       "      <th>WAP005</th>\n",
       "      <th>WAP006</th>\n",
       "      <th>WAP007</th>\n",
       "      <th>WAP008</th>\n",
       "      <th>WAP009</th>\n",
       "      <th>WAP010</th>\n",
       "      <th>...</th>\n",
       "      <th>WAP520</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>FLOOR</th>\n",
       "      <th>BUILDINGID</th>\n",
       "      <th>SPACEID</th>\n",
       "      <th>RELATIVEPOSITION</th>\n",
       "      <th>USERID</th>\n",
       "      <th>PHONEID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>-7515.916799</td>\n",
       "      <td>4.864890e+06</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1380872703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>-7383.867221</td>\n",
       "      <td>4.864840e+06</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1381155054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>-7374.302080</td>\n",
       "      <td>4.864847e+06</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1381155095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>-7365.824883</td>\n",
       "      <td>4.864843e+06</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1381155138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>-7641.499303</td>\n",
       "      <td>4.864922e+06</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1380877774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 529 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   WAP001  WAP002  WAP003  WAP004  WAP005  WAP006  WAP007  WAP008  WAP009  \\\n",
       "0     100     100     100     100     100     100     100     100     100   \n",
       "1     100     100     100     100     100     100     100     100     100   \n",
       "2     100     100     100     100     100     100     100     100     100   \n",
       "3     100     100     100     100     100     100     100     100     100   \n",
       "4     100     100     100     100     100     100     100     100     100   \n",
       "\n",
       "   WAP010     ...      WAP520    LONGITUDE      LATITUDE  FLOOR  BUILDINGID  \\\n",
       "0     100     ...         100 -7515.916799  4.864890e+06      1           1   \n",
       "1     100     ...         100 -7383.867221  4.864840e+06      4           2   \n",
       "2     100     ...         100 -7374.302080  4.864847e+06      4           2   \n",
       "3     100     ...         100 -7365.824883  4.864843e+06      4           2   \n",
       "4     100     ...         100 -7641.499303  4.864922e+06      2           0   \n",
       "\n",
       "   SPACEID  RELATIVEPOSITION  USERID  PHONEID   TIMESTAMP  \n",
       "0        0                 0       0        0  1380872703  \n",
       "1        0                 0       0       13  1381155054  \n",
       "2        0                 0       0       13  1381155095  \n",
       "3        0                 0       0       13  1381155138  \n",
       "4        0                 0       0        2  1380877774  \n",
       "\n",
       "[5 rows x 529 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testingData = pd.read_csv(\"data/validationData.csv\")\n",
    "testingData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testingData[\"combine\"] = testingData[\"FLOOR\"].map(str) + testingData[\"BUILDINGID\"].map(str) + testingData[\"SPACEID\"].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainingData[\"combine\"] = trainingData[\"FLOOR\"].map(str) + trainingData[\"BUILDINGID\"].map(str) + trainingData[\"SPACEID\"].map(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop unnecessary columns. \n",
    "So here we need to predict the longitude and latitude of GPS, which can be done using the WAP columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = trainingData.drop(['FLOOR', 'BUILDINGID','SPACEID','combine','LONGITUDE','LATITUDE','RELATIVEPOSITION','USERID','PHONEID','TIMESTAMP'], axis=1)\n",
    "y_train = trainingData[['LONGITUDE','LATITUDE']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert it into an array, removing the headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values\n",
    "y_train = y_train.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  -7541.2643, 4864920.7782],\n",
       "       [  -7536.6212, 4864934.2252],\n",
       "       [  -7519.1524, 4864949.5322],\n",
       "       ...,\n",
       "       [  -7516.8415, 4864889.291 ],\n",
       "       [  -7537.3219, 4864895.7757],\n",
       "       [  -7536.1658, 4864897.8592]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = testingData.drop(['FLOOR', 'BUILDINGID','SPACEID','combine','LONGITUDE','LATITUDE','RELATIVEPOSITION','USERID','PHONEID','TIMESTAMP'], axis=1)\n",
    "y_test = testingData[['LONGITUDE','LATITUDE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test = (X_train.replace(to_replace=100,value=np.nan))\n",
    "\n",
    "# # Perform the same transform on Test data\n",
    "# y_test = (y_test.replace(to_replace=100,value=np.nan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(\"Before sample removal:\", len(X_train))\n",
    "\n",
    "# y_train = (y_train.loc[X_train.notnull().any(axis=1),:])\n",
    "\n",
    "# X_train = (X_train.loc[X_train.notnull().any(axis=1),:])\n",
    "\n",
    "\n",
    "# print(\"After sample removal:\", len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_exp_train = np.power(10,X_train/10,)\n",
    "X_exp_test = np.power(10,X_test/10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.e+10, 1.e+10, 1.e+10, ..., 1.e+10, 1.e+10, 1.e+10],\n",
       "       [1.e+10, 1.e+10, 1.e+10, ..., 1.e+10, 1.e+10, 1.e+10],\n",
       "       [1.e+10, 1.e+10, 1.e+10, ..., 1.e+10, 1.e+10, 1.e+10],\n",
       "       ...,\n",
       "       [1.e+10, 1.e+10, 1.e+10, ..., 1.e+10, 1.e+10, 1.e+10],\n",
       "       [1.e+10, 1.e+10, 1.e+10, ..., 1.e+10, 1.e+10, 1.e+10],\n",
       "       [1.e+10, 1.e+10, 1.e+10, ..., 1.e+10, 1.e+10, 1.e+10]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_exp_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = testingData.drop(['FLOOR', 'BUILDINGID','SPACEID','combine'], axis=1)\n",
    "y = testingData['combine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = trainingData.drop(['FLOOR', 'BUILDINGID','SPACEID','combine'], axis=1)\n",
    "y = trainingData['combine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chuda\\Anaconda3\\envs\\ADS-assignment1\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Importing Libraries\n",
    "from sklearn.metrics import r2_score, mean_squared_error,mean_absolute_error\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "\n",
    "rmse_dict = {}    \n",
    "def rmse(correct,estimated):\n",
    "    rmse_val = np.sqrt(mean_squared_error(correct,estimated)) \n",
    "    return rmse_val\n",
    "\n",
    "# Generating the Table Frame for metrics\n",
    "evluation_table = pd.DataFrame({  'Model_desc':[],\n",
    "                        'Model_param':[],\n",
    "                        'r2_train': [],\n",
    "                        'r2_test': [],\n",
    "                        'rms_train':[], \n",
    "                        'rms_test': [],\n",
    "                        'mae_train': [],\n",
    "                        'mae_test': [],\n",
    "                        'mape_train':[],\n",
    "                        'mape_test':[],\n",
    "                        'cross_val_score' : []})\n",
    "\n",
    "\n",
    "# Evaluating the model\n",
    "def evaluate_model(model, model_desc,model_param, X_train, y_train, X_test, y_test):\n",
    "    global evluation_table\n",
    "    \n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "        \n",
    "    \n",
    "    try:\n",
    "        r2_train = r2_score(y_train, y_train_pred)\n",
    "        r2_test = r2_score(y_test, y_test_pred)\n",
    "    except:\n",
    "        r2_train = \"not calculated\"\n",
    "        r2_test = \"not calculated\"\n",
    "    try:\n",
    "        rms_train = rmse(y_train, y_train_pred)\n",
    "        rms_test = rmse(y_test, y_test_pred)\n",
    "    except:\n",
    "        rms_train = \"not calculated\"\n",
    "        rms_test = \"not calculated\"\n",
    "    try:\n",
    "        mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "        mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "    except:\n",
    "        mae_train = \"not calculated\"\n",
    "        mae_test = \"not calculated\"\n",
    "    try:\n",
    "        mape_train = np.mean(np.abs((y_train - y_train_pred) / y_train)) * 100\n",
    "        mape_test = np.mean(np.abs((y_test - y_test_pred) / y_test)) * 100\n",
    "    except:\n",
    "        mape_train = \"not calculated\"\n",
    "        mape_test = \"not calculated\"\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        cv_score = cross_val_score(model, X_train, y_train, cv=10)\n",
    "        cv_score = cv_score.mean()\n",
    "    except:\n",
    "        cv_score = \"Not calulated\"\n",
    "        \n",
    "    model_param = pd.DataFrame({'Model_desc':[model_desc],\n",
    "                            'Model_param':[model_param],\n",
    "                            'r2_train': [r2_train],\n",
    "                            'r2_test': [r2_test],\n",
    "                            'rms_train':[rms_train], \n",
    "                            'rms_test': [rms_test],\n",
    "                            'mae_train': [mae_train],\n",
    "                            'mae_test': [mae_test],\n",
    "                            'mape_train':[mape_train],\n",
    "                            'mape_test':[mape_test],\n",
    "                            'cross_val_score' : [cv_score]})\n",
    "\n",
    "    evluation_table = evluation_table.append([model_param])\n",
    " \n",
    "    return evluation_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features=10, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=10, n_jobs=-1, oob_score=False, random_state=None,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = RandomForestRegressor(max_features=10 , n_jobs=-1 )\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model_desc</th>\n",
       "      <th>Model_param</th>\n",
       "      <th>cross_val_score</th>\n",
       "      <th>mae_test</th>\n",
       "      <th>mae_train</th>\n",
       "      <th>mape_test</th>\n",
       "      <th>mape_train</th>\n",
       "      <th>r2_test</th>\n",
       "      <th>r2_train</th>\n",
       "      <th>rms_test</th>\n",
       "      <th>rms_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>(DecisionTreeRegressor(criterion='mse', max_de...</td>\n",
       "      <td>0.98074</td>\n",
       "      <td>884.28989</td>\n",
       "      <td>362.743111</td>\n",
       "      <td>not calculated</td>\n",
       "      <td>not calculated</td>\n",
       "      <td>0.982631</td>\n",
       "      <td>0.995385</td>\n",
       "      <td>1676.686771</td>\n",
       "      <td>866.551088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model_desc                                        Model_param  \\\n",
       "0  RandomForestRegressor  (DecisionTreeRegressor(criterion='mse', max_de...   \n",
       "\n",
       "   cross_val_score   mae_test   mae_train       mape_test      mape_train  \\\n",
       "0          0.98074  884.28989  362.743111  not calculated  not calculated   \n",
       "\n",
       "    r2_test  r2_train     rms_test   rms_train  \n",
       "0  0.982631  0.995385  1676.686771  866.551088  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(classifier, \"RandomForestRegressor\",classifier,X_train,y_train, X_test , y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_param_grid = {}\n",
    "model_scores = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_crossval(reg_list,reg_labels, model_param_grid=model_param_grid, model_scores = model_scores,\n",
    "                    X = X_train, y= y_train, label_extension = None):\n",
    "    '''\n",
    "    Inputs:\n",
    "    reg_model        : List of Regression model instances\n",
    "    reg_label        : List of Regression model labels\n",
    "    model_param_grid : List of parameter grids\n",
    "    X                : explanatory variables \n",
    "    y                : response variable array\n",
    "    model_scores     : Dictionary to store nested cross-validation scores\n",
    "    label_extension  : Extension to regression label in model_scores key\n",
    "    \n",
    "    Outputs:\n",
    "    model_scores     : Updated dictionary of nested cross-validation scores\n",
    "    '''\n",
    "\n",
    "    \n",
    "    for reg_model, reg_label in zip(reg_list, reg_labels):\n",
    "    \n",
    "        #print(param_grid)\n",
    "    \n",
    "        gs = (GridSearchCV(estimator=reg_model, \n",
    "                            param_grid=model_param_grid[reg_label], \n",
    "                            cv=2,\n",
    "                            scoring = 'neg_mean_squared_error',\n",
    "                            n_jobs = 1))\n",
    "    \n",
    "        scores = cross_val_score(estimator=gs,\n",
    "                                 X=X,\n",
    "                                 y=y,\n",
    "                                 cv=5,\n",
    "                                 scoring='neg_mean_squared_error')\n",
    "        scores = np.sqrt(np.abs(scores))\n",
    "        \n",
    "        if label_extension:\n",
    "            reg_label += '_' + label_extension\n",
    "        \n",
    "        print(\"RMSE: %0.2f (+/- %0.2f) [%s]\"\n",
    "              % (scores.mean(), scores.std(), reg_label))\n",
    "        \n",
    "        model_scores[reg_label] = scores\n",
    "        \n",
    "    \n",
    "    return model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 4283.88 (+/- 66.23) [Ridge]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chuda\\Anaconda3\\envs\\ADS-assignment1\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\chuda\\Anaconda3\\envs\\ADS-assignment1\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\chuda\\Anaconda3\\envs\\ADS-assignment1\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\chuda\\Anaconda3\\envs\\ADS-assignment1\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\chuda\\Anaconda3\\envs\\ADS-assignment1\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\chuda\\Anaconda3\\envs\\ADS-assignment1\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\chuda\\Anaconda3\\envs\\ADS-assignment1\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\chuda\\Anaconda3\\envs\\ADS-assignment1\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\chuda\\Anaconda3\\envs\\ADS-assignment1\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\chuda\\Anaconda3\\envs\\ADS-assignment1\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\chuda\\Anaconda3\\envs\\ADS-assignment1\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\chuda\\Anaconda3\\envs\\ADS-assignment1\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\chuda\\Anaconda3\\envs\\ADS-assignment1\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\chuda\\Anaconda3\\envs\\ADS-assignment1\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\chuda\\Anaconda3\\envs\\ADS-assignment1\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\chuda\\Anaconda3\\envs\\ADS-assignment1\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\chuda\\Anaconda3\\envs\\ADS-assignment1\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\chuda\\Anaconda3\\envs\\ADS-assignment1\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 4270.43 (+/- 61.54) [Lasso]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Linear Models\n",
    "\n",
    "# Ridge Regression\n",
    "pipe_ridge = Pipeline([('scl', StandardScaler()),\n",
    "            ('reg', Ridge(random_state=1))])\n",
    "\n",
    "# Lasso\n",
    "pipe_lasso = Pipeline([('scl', StandardScaler()),\n",
    "            ('reg', Lasso(random_state=1))])\n",
    "\n",
    "param_grid_lm= {\n",
    "    'reg__alpha':[0.01,0.1,1,10],\n",
    "}\n",
    "\n",
    "reg_lm = [pipe_ridge,pipe_lasso]\n",
    "reg_labels_lm = ['Ridge','Lasso']\n",
    "model_param_grid['Ridge'] = param_grid_lm\n",
    "model_param_grid['Lasso'] = param_grid_lm\n",
    "\n",
    "model_scores = nested_crossval(reg_lm,reg_labels_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Random Forests\n",
    "reg_rf = RandomForestRegressor(random_state=1)\n",
    "\n",
    "# Extra Trees\n",
    "reg_et = ExtraTreesRegressor(random_state=1)\n",
    "\n",
    "param_grid_tree = {\n",
    "    'n_jobs': [-1],\n",
    "    'n_estimators': [10,30,50,70,100],\n",
    "    'max_features': [0.25,0.5,0.75],\n",
    "    'max_depth': [3,6,9,12],\n",
    "    'min_samples_leaf': [5,10,20,30]\n",
    "}\n",
    "\n",
    "reg_tree = [reg_rf,reg_et]\n",
    "reg_labels_tree = ['Random Forests','Extra Trees']\n",
    "model_param_grid['Random Forests'] = param_grid_tree\n",
    "model_param_grid['Extra Trees'] = param_grid_tree\n",
    "\n",
    "model_scores = nested_crossval(reg_tree,reg_labels_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_knn = Pipeline([('scl', StandardScaler()),\n",
    "            ('reg', KNeighborsRegressor())])\n",
    "\n",
    "grid_param_knn = {\n",
    "    'reg__n_neighbors': [2,3,5,7],\n",
    "    'reg__weights': ['uniform','distance'],\n",
    "    'reg__metric': ['euclidean','minkowski','manhattan'],\n",
    "    'reg__n_jobs': [-1]\n",
    "}\n",
    "\n",
    "model_param_grid['KNN'] = grid_param_knn\n",
    "\n",
    "model_scores = nested_crossval([pipe_knn],['KNN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "neigh = KNeighborsRegressor(n_neighbors=2)\n",
    "neigh.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(neigh, \"RandomForestClassifier\",neigh,X_train,y_train, X_test , y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot import TPOTRegressor\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_config_dict = {\n",
    "        'sklearn.ensemble.ExtraTreesRegressor': {\n",
    "        'n_estimators': [100],\n",
    "        'max_features': np.arange(0.05, 1.01, 0.05),\n",
    "        'min_samples_split': range(2, 21),\n",
    "        'min_samples_leaf': range(1, 21),\n",
    "        'bootstrap': [True, False]\n",
    "    },\n",
    "\n",
    "    'sklearn.ensemble.GradientBoostingRegressor': {\n",
    "        'n_estimators': [100],\n",
    "        'loss': [\"ls\", \"lad\", \"huber\", \"quantile\"],\n",
    "        'learning_rate': [1e-3, 1e-2, 1e-1, 0.5, 1.],\n",
    "        'max_depth': range(1, 11),\n",
    "        'min_samples_split': range(2, 21),\n",
    "        'min_samples_leaf': range(1, 21),\n",
    "        'subsample': np.arange(0.05, 1.01, 0.05),\n",
    "        'max_features': np.arange(0.05, 1.01, 0.05),\n",
    "        'alpha': [0.75, 0.8, 0.85, 0.9, 0.95, 0.99]\n",
    "    },\n",
    "\n",
    "    'sklearn.ensemble.AdaBoostRegressor': {\n",
    "        'n_estimators': [100],\n",
    "        'learning_rate': [1e-3, 1e-2, 1e-1, 0.5, 1.],\n",
    "        'loss': [\"linear\", \"square\", \"exponential\"],\n",
    "        'max_depth': range(1, 11)\n",
    "    },\n",
    "\n",
    "    'sklearn.tree.DecisionTreeRegressor': {\n",
    "        'max_depth': range(1, 11),\n",
    "        'min_samples_split': range(2, 21),\n",
    "        'min_samples_leaf': range(1, 21)\n",
    "    },\n",
    "\n",
    "    'sklearn.neighbors.KNeighborsRegressor': {\n",
    "        'n_neighbors': range(1, 101),\n",
    "        'weights': [\"uniform\", \"distance\"],\n",
    "        'p': [1, 2]\n",
    "    },\n",
    "\n",
    "    'sklearn.linear_model.LassoLarsCV': {\n",
    "        'normalize': [True, False]\n",
    "    },\n",
    "\n",
    "    'sklearn.svm.LinearSVR': {\n",
    "        'loss': [\"epsilon_insensitive\", \"squared_epsilon_insensitive\"],\n",
    "        'dual': [True, False],\n",
    "        'tol': [1e-5, 1e-4, 1e-3, 1e-2, 1e-1],\n",
    "        'C': [1e-4, 1e-3, 1e-2, 1e-1, 0.5, 1., 5., 10., 15., 20., 25.],\n",
    "        'epsilon': [1e-4, 1e-3, 1e-2, 1e-1, 1.]\n",
    "    },\n",
    "\n",
    "    'sklearn.ensemble.RandomForestRegressor': {\n",
    "        'n_estimators': [100],\n",
    "        'max_features': np.arange(0.05, 1.01, 0.05),\n",
    "        'min_samples_split': range(2, 21),\n",
    "        'min_samples_leaf': range(1, 21),\n",
    "        'bootstrap': [True, False]\n",
    "    },\n",
    "    'sklearn.linear_model.RidgeCV': {\n",
    "    },\n",
    "\n",
    "    'xgboost.XGBRegressor': {\n",
    "        'n_estimators': [100],\n",
    "        'max_depth': range(1, 11),\n",
    "        'learning_rate': [1e-3, 1e-2, 1e-1, 0.5, 1.],\n",
    "        'subsample': np.arange(0.05, 1.01, 0.05),\n",
    "        'min_child_weight': range(1, 21),\n",
    "        'nthread': [1]\n",
    "    },\n",
    "    'sklearn.preprocessing.Binarizer': {\n",
    "        'threshold': np.arange(0.0, 1.01, 0.05)\n",
    "    },\n",
    "\n",
    "    'sklearn.decomposition.FastICA': {\n",
    "        'tol': np.arange(0.0, 1.01, 0.05)\n",
    "    },\n",
    "\n",
    "    'sklearn.cluster.FeatureAgglomeration': {\n",
    "        'linkage': ['ward', 'complete', 'average'],\n",
    "        'affinity': ['euclidean', 'l1', 'l2', 'manhattan', 'cosine']\n",
    "    },\n",
    "\n",
    "    'sklearn.preprocessing.MaxAbsScaler': {\n",
    "    },\n",
    "\n",
    "    'sklearn.preprocessing.MinMaxScaler': {\n",
    "    },\n",
    "\n",
    "    'sklearn.preprocessing.Normalizer': {\n",
    "        'norm': ['l1', 'l2', 'max']\n",
    "    },\n",
    "\n",
    "    'sklearn.kernel_approximation.Nystroem': {\n",
    "        'kernel': ['rbf', 'cosine', 'chi2', 'laplacian', 'polynomial', 'poly', 'linear', 'additive_chi2', 'sigmoid'],\n",
    "        'gamma': np.arange(0.0, 1.01, 0.05),\n",
    "        'n_components': range(1, 11)\n",
    "    },\n",
    "\n",
    "    'sklearn.decomposition.PCA': {\n",
    "        'svd_solver': ['randomized'],\n",
    "        'iterated_power': range(1, 11)\n",
    "    },\n",
    "\n",
    "    'sklearn.preprocessing.PolynomialFeatures': {\n",
    "        'degree': [2],\n",
    "        'include_bias': [False],\n",
    "        'interaction_only': [False]\n",
    "    },\n",
    "\n",
    "    'sklearn.kernel_approximation.RBFSampler': {\n",
    "        'gamma': np.arange(0.0, 1.01, 0.05)\n",
    "    },\n",
    "\n",
    "    'sklearn.preprocessing.RobustScaler': {\n",
    "    },\n",
    "\n",
    "    'sklearn.preprocessing.StandardScaler': {\n",
    "    },\n",
    "\n",
    "    'tpot.builtins.ZeroCount': {\n",
    "    },\n",
    "\n",
    "    'tpot.builtins.OneHotEncoder': {\n",
    "        'minimum_fraction': [0.05, 0.1, 0.15, 0.2, 0.25],\n",
    "        'sparse': [False]\n",
    "    },\n",
    "\n",
    "    # Selectors\n",
    "    'sklearn.feature_selection.SelectFwe': {\n",
    "        'alpha': np.arange(0, 0.05, 0.001),\n",
    "        'score_func': {\n",
    "            'sklearn.feature_selection.f_regression': None\n",
    "        }\n",
    "    },\n",
    "\n",
    "    'sklearn.feature_selection.SelectPercentile': {\n",
    "        'percentile': range(1, 100),\n",
    "        'score_func': {\n",
    "            'sklearn.feature_selection.f_regression': None\n",
    "        }\n",
    "    },\n",
    "\n",
    "    'sklearn.feature_selection.VarianceThreshold': {\n",
    "        'threshold': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.2]\n",
    "    },\n",
    "\n",
    "    'sklearn.feature_selection.SelectFromModel': {\n",
    "        'threshold': np.arange(0, 1.01, 0.05),\n",
    "        'estimator': {\n",
    "            'sklearn.ensemble.ExtraTreesRegressor': {\n",
    "                'n_estimators': [100],\n",
    "                'max_features': np.arange(0.05, 1.01, 0.05)\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version 0.9.2 of tpot is outdated. Version 0.9.3 was released 1 day ago.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error: Input data is not in a valid format. Please confirm that the input data is scikit-learn compatible. For example, the features must be a 2-D array and target labels must be a 1-D array.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\learn_python\\lib\\site-packages\\tpot\\base.py\u001b[0m in \u001b[0;36m_check_dataset\u001b[1;34m(self, features, target)\u001b[0m\n\u001b[0;32m   1027\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1028\u001b[1;33m             \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1029\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mAssertionError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\learn_python\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 578\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    579\u001b[0m         \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\learn_python\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[1;34m(y, warn)\u001b[0m\n\u001b[0;32m    613\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 614\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"bad input shape {0}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    615\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: bad input shape (19937, 2)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-85613aea0262>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtpot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTPOTRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpopulation_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbosity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mperiodic_checkpoint_folder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"./optCode/\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtpot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtpot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtpot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tpot_final_pipeline.py'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\learn_python\\lib\\site-packages\\tpot\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, features, target, sample_weight, groups)\u001b[0m\n\u001b[0;32m    561\u001b[0m                 \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_impute_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 563\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    564\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m         \u001b[1;31m# Randomly collect a subsample of training samples for pipeline optimization process.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\learn_python\\lib\\site-packages\\tpot\\base.py\u001b[0m in \u001b[0;36m_check_dataset\u001b[1;34m(self, features, target)\u001b[0m\n\u001b[0;32m   1029\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mAssertionError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1030\u001b[0m             raise ValueError(\n\u001b[1;32m-> 1031\u001b[1;33m                 \u001b[1;34m'Error: Input data is not in a valid format. Please confirm '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1032\u001b[0m                 \u001b[1;34m'that the input data is scikit-learn compatible. For example, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1033\u001b[0m                 \u001b[1;34m'the features must be a 2-D array and target labels must be a '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error: Input data is not in a valid format. Please confirm that the input data is scikit-learn compatible. For example, the features must be a 2-D array and target labels must be a 1-D array."
     ]
    }
   ],
   "source": [
    "tpot = TPOTRegressor(generations=10, population_size=10, verbosity=2, n_jobs=-1, periodic_checkpoint_folder=\"./optCode/\")\n",
    "tpot.fit(X_train, y_train)\n",
    "print(tpot.score(X_test, y_test))\n",
    "tpot.export('tpot_final_pipeline.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from boruta import BorutaPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.75, test_size = 0.25)\n",
    "\n",
    "# define random forest classifier, with utilising all cores and\n",
    "# sampling in proportion to y labels\n",
    "forest = RandomForestClassifier(n_jobs=-1)\n",
    " \n",
    "# define Boruta feature selection method\n",
    "feat_selector = BorutaPy(forest, n_estimators='auto', verbose=2)\n",
    " \n",
    "# find all relevant features\n",
    "feat_selector.fit(X_train, y_train)\n",
    " \n",
    "# check selected features\n",
    "feat_selector.support_\n",
    " \n",
    "# check ranking of features\n",
    "feat_selector.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = MinMaxScaler()\n",
    "X = min_max_scaler.fit_transform(X)\n",
    "# split into train and test sets\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# design network\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs=100, batch_size=1, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "# plot history\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(test_X)\n",
    "yhat\n",
    "rmse = sqrt(mean_squared_error(test_y, yhat))\n",
    "print('Test RMSE: %.3f' % rmse)\n",
    "r2_score(test_y, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
